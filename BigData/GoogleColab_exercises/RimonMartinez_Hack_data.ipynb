{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTZU8a1OHneL",
        "outputId": "5adad55e-055e-4ee9-8ece-fcdd6c9b7a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,056 kB]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,234 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,094 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [30.0 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,143 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,342 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,567 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,307 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,519 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,347 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Fetched 18.0 MB in 7s (2,695 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "appname = \"K-Means Clustering - Documentation example\"\n",
        "\n",
        "# Look into https://spark.apache.org/downloads.html for the latest version\n",
        "spark_mirror = \"https://mirrors.sonic.net/apache/spark\"\n",
        "spark_version = \"3.3.1\"\n",
        "hadoop_version = \"3\"\n",
        "\n",
        "# Install Java 8 (Spark does not work with newer Java versions)\n",
        "! apt-get update\n",
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download and extract Spark binary distribution\n",
        "! rm -rf spark-{spark_version}-bin-hadoop{hadoop_version}.tgz spark-{spark_version}-bin-hadoop{hadoop_version}\n",
        "! wget -q {spark_mirror}/spark-{spark_version}/spark-{spark_version}-bin-hadoop{hadoop_version}.tgz\n",
        "! tar xzf spark-{spark_version}-bin-hadoop{hadoop_version}.tgz\n",
        "\n",
        "# The only 2 environment variables needed to set up Java and Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/spark-{spark_version}-bin-hadoop{hadoop_version}\"\n",
        "\n",
        "# Set up the Spark environment based on the environment variable SPARK_HOME \n",
        "! pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Get the Spark session object (basic entry point for every operation)\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(appname).master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DOWNLOAD AND READ THE FILES\n",
        "from google.colab import files \n",
        "  \n",
        "hack = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "LlYB-PtgVJgi",
        "outputId": "7d341a1d-bb76-4cec-9963-0b0ddc27547e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-168b3aaf-72c5-4591-b080-5c3d18f2ed81\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-168b3aaf-72c5-4591-b080-5c3d18f2ed81\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hack_data.csv to hack_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.options(inferSchema=True, header=True).csv('hack_data.csv')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBbP0OU4VjYt",
        "outputId": "049c4a24-08c0-44a5-8c97-4e58a9f08878"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+\n",
            "|Session_Connection_Time|Bytes Transferred|Kali_Trace_Used|Servers_Corrupted|Pages_Corrupted|            Location|WPM_Typing_Speed|\n",
            "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+\n",
            "|                    8.0|           391.09|              1|             2.96|            7.0|            Slovenia|           72.37|\n",
            "|                   20.0|           720.99|              0|             3.04|            9.0|British Virgin Is...|           69.08|\n",
            "|                   31.0|           356.32|              1|             3.71|            8.0|             Tokelau|           70.58|\n",
            "|                    2.0|           228.08|              1|             2.48|            8.0|             Bolivia|            70.8|\n",
            "|                   20.0|            408.5|              0|             3.57|            8.0|                Iraq|           71.28|\n",
            "|                    1.0|           390.69|              1|             2.79|            9.0|    Marshall Islands|           71.57|\n",
            "|                   18.0|           342.97|              1|              5.1|            7.0|             Georgia|           72.32|\n",
            "|                   22.0|           101.61|              1|             3.03|            7.0|         Timor-Leste|           72.03|\n",
            "|                   15.0|           275.53|              1|             3.53|            8.0|Palestinian Terri...|           70.17|\n",
            "|                   12.0|           424.83|              1|             2.53|            8.0|          Bangladesh|           69.99|\n",
            "|                   15.0|           249.09|              1|             3.39|            9.0|Northern Mariana ...|           70.77|\n",
            "|                   32.0|           242.48|              0|             4.24|            8.0|            Zimbabwe|           67.93|\n",
            "|                   23.0|           514.54|              0|             3.18|            8.0|         Isle of Man|           68.56|\n",
            "|                    9.0|           284.77|              0|             3.12|            9.0|Sao Tome and Prin...|           70.82|\n",
            "|                   27.0|           779.25|              1|             2.37|            8.0|              Greece|           72.73|\n",
            "|                   12.0|           307.31|              1|             3.22|            7.0|     Solomon Islands|           67.95|\n",
            "|                   21.0|           355.94|              1|              2.0|            7.0|       Guinea-Bissau|            72.0|\n",
            "|                   10.0|           372.65|              0|             3.33|            7.0|        Burkina Faso|           69.19|\n",
            "|                   20.0|           347.23|              1|             2.33|            7.0|            Mongolia|           70.41|\n",
            "|                   22.0|           456.57|              0|             1.52|            8.0|             Nigeria|           69.35|\n",
            "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWvUeMV3XZEc",
        "outputId": "8f8e17f5-f0bc-4896-b9af-d473f49bae08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Session_Connection_Time: double (nullable = true)\n",
            " |-- Bytes Transferred: double (nullable = true)\n",
            " |-- Kali_Trace_Used: integer (nullable = true)\n",
            " |-- Servers_Corrupted: double (nullable = true)\n",
            " |-- Pages_Corrupted: double (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- WPM_Typing_Speed: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf6tTzxrXdzB",
        "outputId": "98d5c8a7-13f8-4460-d69e-88cdc6cc23a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+------------------+------------------+-----------------+------------------+-----------+------------------+\n",
            "|summary|Session_Connection_Time| Bytes Transferred|   Kali_Trace_Used|Servers_Corrupted|   Pages_Corrupted|   Location|  WPM_Typing_Speed|\n",
            "+-------+-----------------------+------------------+------------------+-----------------+------------------+-----------+------------------+\n",
            "|  count|                    334|               334|               334|              334|               334|        334|               334|\n",
            "|   mean|     30.008982035928145| 607.2452694610777|0.5119760479041916|5.258502994011977|10.838323353293413|       null|57.342395209580864|\n",
            "| stddev|     14.088200614636158|286.33593163576757|0.5006065264451406| 2.30190693339697|  3.06352633036022|       null| 13.41106336843464|\n",
            "|    min|                    1.0|              10.0|                 0|              1.0|               6.0|Afghanistan|              40.0|\n",
            "|    max|                   60.0|            1330.5|                 1|             10.0|              15.0|   Zimbabwe|              75.0|\n",
            "+-------+-----------------------+------------------+------------------+-----------------+------------------+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Feature Set"
      ],
      "metadata": {
        "id": "P_X6VWR7YYk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VECTORASSEMBLER ASSEMBLES ALL THE FEATURES INTO ONE VECTOR FROM MULTIPLE COLUMNS THAT CONTAIN TYPE DOUBLE. \n",
        "features = [ 'Session_Connection_Time', 'Bytes Transferred', 'Kali_Trace_Used', 'Servers_Corrupted', 'Pages_Corrupted', 'WPM_Typing_Speed']\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
        "with_features = assembler.transform(df).select('features')\n",
        "with_features.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZztOczwYW-C",
        "outputId": "0ee94507-b0cc-49b1-ecfe-e46a695624c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[8.0,391.09,1.0,2...|\n",
            "|[20.0,720.99,0.0,...|\n",
            "|[31.0,356.32,1.0,...|\n",
            "|[2.0,228.08,1.0,2...|\n",
            "|[20.0,408.5,0.0,3...|\n",
            "|[1.0,390.69,1.0,2...|\n",
            "|[18.0,342.97,1.0,...|\n",
            "|[22.0,101.61,1.0,...|\n",
            "|[15.0,275.53,1.0,...|\n",
            "|[12.0,424.83,1.0,...|\n",
            "|[15.0,249.09,1.0,...|\n",
            "|[32.0,242.48,0.0,...|\n",
            "|[23.0,514.54,0.0,...|\n",
            "|[9.0,284.77,0.0,3...|\n",
            "|[27.0,779.25,1.0,...|\n",
            "|[12.0,307.31,1.0,...|\n",
            "|[21.0,355.94,1.0,...|\n",
            "|[10.0,372.65,0.0,...|\n",
            "|[20.0,347.23,1.0,...|\n",
            "|[22.0,456.57,0.0,...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Scaling"
      ],
      "metadata": {
        "id": "sDW7-wOAbJKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
        "scalar_model = scaler.fit(with_features)\n",
        "scaled_data = scalar_model.transform(with_features)\n",
        "scaled_data.select('scaled_features').head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnztDUNQbCK_",
        "outputId": "4c031a1d-3b84-4620-e437-e281026df517"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(scaled_features=DenseVector([0.5679, 1.3658, 1.9976, 1.2859, 2.2849, 5.3963]))]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train KMeans Model and Interpret Cluster Results"
      ],
      "metadata": {
        "id": "hHKUz2EzZIf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "import numpy as np\n",
        "\n",
        "evaluator = ClusteringEvaluator(metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
        "# let's try several different values of k\n",
        "ka = [3, 2, 4, 5]\n",
        "silhouette = np.zeros(len(ka))\n",
        "model = np.zeros(len(ka))\n",
        "results = []\n",
        "for i in range(len(ka)):\n",
        "  kmeans = KMeans(featuresCol='scaled_features', k= ka[i])\n",
        "  model = kmeans.fit(scaled_data)\n",
        "\n",
        "  result = model.transform(scaled_data)\n",
        "  results.append(result)\n",
        "  silhouette[i] = evaluator.evaluate(result)\n",
        "\n",
        "\n",
        "maxProbability = max(silhouette)\n",
        "idxMaxProbability = np.argmax(silhouette)\n",
        "numHackers = ka[idxMaxProbability]\n",
        "print(f\"idx:{np.argmax(silhouette)}, Max silhouette: {max(silhouette)}, k Max silhouette: {ka[np.argmax(silhouette)]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwZEY8AAfSDD",
        "outputId": "0adef735-4ec2-4917-8e69-86798dcdf2b3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx:1, Max silhouette: 0.6683623593283755, k Max silhouette: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, of all the possibilities we have covered for k (from 2 to 5), grouping in 2 clusters is the option that makes the most sense, so we deduce in the end that it was 2 hackers who carried out the crime.\n"
      ],
      "metadata": {
        "id": "hnT_-vA7ZLjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get clustering results"
      ],
      "metadata": {
        "id": "h0gdjEqmZA4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results[idxMaxProbability].show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5ftopPiUXx-",
        "outputId": "089062ab-f366-4308-e7c7-bb743e05d869"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+\n",
            "|            features|     scaled_features|prediction|\n",
            "+--------------------+--------------------+----------+\n",
            "|[8.0,391.09,1.0,2...|[0.56785108466505...|         1|\n",
            "|[20.0,720.99,0.0,...|[1.41962771166263...|         1|\n",
            "|[31.0,356.32,1.0,...|[2.20042295307707...|         1|\n",
            "|[2.0,228.08,1.0,2...|[0.14196277116626...|         1|\n",
            "|[20.0,408.5,0.0,3...|[1.41962771166263...|         1|\n",
            "|[1.0,390.69,1.0,2...|[0.07098138558313...|         1|\n",
            "|[18.0,342.97,1.0,...|[1.27766494049636...|         1|\n",
            "|[22.0,101.61,1.0,...|[1.56159048282889...|         1|\n",
            "|[15.0,275.53,1.0,...|[1.06472078374697...|         1|\n",
            "|[12.0,424.83,1.0,...|[0.85177662699757...|         1|\n",
            "|[15.0,249.09,1.0,...|[1.06472078374697...|         1|\n",
            "|[32.0,242.48,0.0,...|[2.27140433866020...|         1|\n",
            "|[23.0,514.54,0.0,...|[1.63257186841202...|         1|\n",
            "|[9.0,284.77,0.0,3...|[0.63883247024818...|         1|\n",
            "|[27.0,779.25,1.0,...|[1.91649741074455...|         1|\n",
            "|[12.0,307.31,1.0,...|[0.85177662699757...|         1|\n",
            "|[21.0,355.94,1.0,...|[1.49060909724576...|         1|\n",
            "|[10.0,372.65,0.0,...|[0.70981385583131...|         1|\n",
            "|[20.0,347.23,1.0,...|[1.41962771166263...|         1|\n",
            "|[22.0,456.57,0.0,...|[1.56159048282889...|         1|\n",
            "+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}